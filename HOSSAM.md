<머신러닝 커리큘럼>
📚 전체 목차 텍스트
🔹 비지도학습 (Unsupervised Learning)
LAB01 비지도학습 | 군집분석 | KMeans
LAB02 비지도학습 | 군집분석 | DBSCAN
LAB03 비지도학습 | 군집분석 | Hierarchical Clustering
LAB04 비지도학습 | 군집분석 | PCA
LAB05 비지도학습 | PBT (프로젝트 기반 탐색)

| 기법               | 핵심 아이디어                     |
| ---------------- | --------------------------- |
| **KMeans**       | 거리 기반으로 K개의 중심을 찾아 데이터를 묶음  |
| **DBSCAN**       | 밀도 기반으로 군집 형성 + 이상치 자동 탐지   |
| **Hierarchical** | 병합/분할 과정으로 군집 구조를 트리 형태로 표현 |
| **PCA**          | 변수 차원을 줄이면서 데이터의 주요 구조 보존   |
| **PBT**          | 데이터 특성 파악 및 군집 결과 해석 실습     |



🔹 지도학습 – 회귀(Regression) 기초
LAB06 지도학습 | 예측 | 선형 | Linear Regression
LAB07 지도학습 | 예측 | 선형 | Ridge
LAB08 지도학습 | 예측 | 선형 | Lasso
LAB09 지도학습 | 예측 | 선형 | SGDRegressor

| 기법                    | 특징                                 |
| --------------------- | ---------------------------------- |
| **Linear Regression** | 가장 기본적인 직선 모델                      |
| **Ridge**             | 계수를 작게 만들어 과적합 방지 (L2 규제)          |
| **Lasso**             | 필요 없는 변수 계수를 0으로 만들어 변수 선택 (L1 규제) |
| **SGDRegressor**      | 대용량 데이터에서 빠르게 학습하는 확률적 경사하강법       |



🔹 지도학습 – 비선형 회귀
LAB10 지도학습 | 예측 | 비선형 | DecisionTreeRegressor
LAB11 지도학습 | 예측 | 비선형 | KNeighborsRegressor
LAB12 지도학습 | 예측 | 비선형 | SVR

| 기법                | 특징                      |
| ----------------- | ----------------------- |
| **Decision Tree** | 데이터를 규칙 기반으로 나눠 예측      |
| **KNN Regressor** | 가까운 이웃의 평균값으로 예측        |
| **SVR**           | 마진 기반으로 오차를 허용하면서 회귀 수행 |



🔹 지도학습 – 앙상블(Ensemble)
LAB13 지도학습 | 예측 | 앙상블 | Voting, Bagging, Boosting 개념
LAB14 지도학습 | 예측 | 앙상블 | RandomForest (Bagging)
LAB15 지도학습 | 예측 | 앙상블 | XGBoost (Boosting)
LAB16 지도학습 | 예측 | 앙상블 | LightGBM (Boosting)
LAB17 지도학습 | 예측 | 앙상블 | CatBoost (Boosting)

| 기법               | 특징                         |
| ---------------- | -------------------------- |
| **Voting**       | 여러 모델의 예측 평균               |
| **Bagging**      | 데이터 샘플을 다르게 해서 여러 모델 학습    |
| **RandomForest** | 여러 개의 트리를 모은 Bagging 대표 모델 |
| **Boosting**     | 이전 모델의 오차를 다음 모델이 보완       |
| **XGBoost**      | 빠르고 강력한 Boosting 알고리즘      |
| **LightGBM**     | 대용량에 최적화된 Boosting         |
| **CatBoost**     | 범주형 데이터 처리에 강한 Boosting    |


=================================================================
📌 선형회귀 분석 전체 프로세스 정리
1️⃣ 변수 유형 파악
🔹 연속형 변수
분포 왜도 확인
왜도가 크면 로그 변환 고려

👉 이때 종속변수도 함께 로그 변환할지 판단

🔹 범주형 변수
모델에 사용하기로 결정했다면
명목형 → 원핫 인코딩
(순서형이면 라벨 인코딩 가능)

2️⃣ 전처리 원칙
항목	처리 방식
로그 변환	독립변수 + 종속변수 모두 가능 (분포 안정 목적)
스케일링	❗ 종속변수는 제외, 독립변수만 수행
전처리 완료 후	엑셀 등으로 저장 → 새로운 주피터 파일에서 분석 시작

3️⃣ 탐색적 확인 (EDA)
변수 단위 차이가 큰지 확인할 때
👉 박스플롯 유용

변수 분포 확인
종속변수와 독립변수 관계 시각화 (산점도)

4️⃣ 모델에 넣을 변수 선택
종속변수에 영향을 주는지 확인 후 포함
필요하다면

교호작용(Interaction) 고려
→ 통계적으로는 이원분산분석(ANOVA) 개념과 연결


5️⃣ 데이터 구조 만들기
| 구분      | 형태                        |
| ------- | ------------------------- |
| 독립변수(X) | **DataFrame 형태 유지**       |
| 종속변수(y) | **Series 또는 Numpy array** |


6️⃣ 데이터 분할
x_train, x_test, y_train, y_test
훈련 데이터: 모델 학습
테스트 데이터: 모델 일반화 성능 확인


7️⃣ 회귀모델 학습 후 해석
| 구성 요소               | 의미                     |
| ------------------- | ---------------------- |
| **기울기(계수, weight)** | 독립변수가 1 증가할 때 종속변수 변화량 |
| **절편(bias)**        | 모든 독립변수가 0일 때 종속변수 값   |
| **추정치(ŷ)**          | 모델이 예측한 값              |


8️⃣ 모델 성능 평가
| 지표            | 설명                      |
| ------------- | ----------------------- |
| **R² (결정계수)** | 모델이 데이터를 얼마나 설명하는지      |
| **훈련 R²**     | 학습 데이터 설명력              |
| **검증 R²**     | 새로운 데이터 설명력 → ❗ 이게 더 중요 |









