{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6a905c",
   "metadata": {},
   "source": [
    "- roll 미루는거\n",
    "- cumsum 누적합\n",
    "-각 구간에서 격차 가 큰 값이 적절한 안정 구간으로 된다\n",
    "(낄이가 가장 긴거)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9e1d6",
   "metadata": {},
   "source": [
    "# [LAB 02] DBSCAN 성능평가\n",
    "\n",
    "## 01.DBSCAN 성능평가 개요\n",
    "\n",
    "### [1] 왜 DBSCAN 은 성능평가가 어려울까?\n",
    "- 정답이 정해진 군집이 아님\n",
    "- 군집수를 자동으로 결정해줌 (k means 처럼 정답 k 가 없음)\n",
    "- 이상치를 허용함 (일부 데이터는 군집에 아예 속하지 않음, 즉 모든 데이터를 평가 대상으로 삼는 지표는 쓰지 못함)\n",
    "- 비구형,비선형 군집\n",
    "- K-MEANS 의 계열 지표와 전제 불일치 (실루엣, inertia 는 모든 점이 군집에 속하고, 군집은 구형이라는 전제가 있음)\n",
    "\n",
    "### [2] 잘못된 접근\n",
    "- 단일 성능 점수로 비교 --> DBSCAN 은 구간 기반 판단\n",
    "- 실루엣 점수만으로 EPS 결정 --> 실루엣에는 NOISE 개념이 없어 보조 지표일 뿐임\n",
    "- K 최적화 관점 적용 --> DBSCAN 은 K 를 찾아내는 것이 아닌 구조의 안정성을 확인해야함\n",
    "\n",
    "\n",
    "### [3] DBSCAN 성능평가의 기본 관점\n",
    "- 예측 성능에 초점 X\n",
    "- 구조 안정성 --> EPS 가 변했을 떄 군집 구조가 흔들리는지?\n",
    "- 이상치 의미--> NOISE 는 쓸모없는 데이터가 아닌 이상 패턴으로 인식\n",
    "- 해석 가능성\n",
    "\n",
    "\n",
    "\n",
    "### [4] 수치화 가능한 평가 지표 (보조적)\n",
    "\n",
    "- 이상치 비율은 $ \\text{Noise ratio} = \\frac{n_{noise}}{n_{total}} $ 로 정의한다.\n",
    "- eps 간 ARI\n",
    "\n",
    "- eps 가 커지면 보통 noise 는 감소\n",
    "\n",
    "### [5] eps grid 기반 성능평가 프레임\n",
    "\n",
    "#### [5.1] eps 후보 설정\n",
    "\n",
    "- k-distance elbow point --> 중심값 , eps 의 기준점 역할\n",
    "- eps rlwns +- 20 -40% --> 이 구간 근저에서 구조의 변화를 봄\n",
    "\n",
    "#### [5.2] eps grid 구성\n",
    "- step : eps x 0.05\n",
    "- 반복횟수 : 10-20회\n",
    "\n",
    "\n",
    "#### [5.3] eps별 계산 지표 , 각 eps 마다 계산하는 지표\n",
    "\n",
    "- 군집 수\n",
    "- 이상치 비율\n",
    "- ARI (Adjusted Rand Index):  \n",
    "  두 군집 결과의 일치도를 무작위 일치 확률을 보정해  \n",
    "  **-1 ~ 1 범위**로 측정하는 군집 안정성 비교 지표, 값이 높을수록 구조가 안정적\n",
    "\n",
    "\n",
    "#### [5.4] 안정 구간의 정의\n",
    "- 좋은 구간을 찾아내는 것이 목적\n",
    "  \n",
    "- ARI ≥ 0.9 유지 (구조 변화 거의 없음)\n",
    "- 군집 수 급변 없음 (갑자기 쪼개지거나 합쳐지지 않음)\n",
    "- 이상치 비율 완만 변화 (noise 가 서서히 변함)\n",
    "- plateau 구간 존재 (지표들이 팽팽하게 유지되는 구간)\n",
    "\n",
    "\n",
    "\n",
    "#### [5.5] 최종 eps 선택 원칙\n",
    "\n",
    "- 단일 최적값 ❌\n",
    "- 안정 구간 ⭕\n",
    "- 구간 내 대표 eps 선택\n",
    "\n",
    "\n",
    "#### [5.6] 목적 기반 평가 연결\n",
    "\n",
    "- 이상치 탐지 목적 --> noise 를 많이 남기는 eps 가 적절\n",
    "- 패턴 탐색 목적 --> 군집 구조가 명확한 eps\n",
    "- 세분화·해석 목적 --> 군집수가 늘어나도 내부 구조를 자세히 볼 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab34f6",
   "metadata": {},
   "source": [
    "## #02. 준비작업\n",
    "### [1] 패키지 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2ffd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hossam import load_data, my_dpi\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from kneed import KneeLocator\n",
    "\n",
    "#성능평가지표\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b638a",
   "metadata": {},
   "source": [
    "### [2] 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168b1148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m게임 이용시간(time spent)과 레벨(game level)에 대한 가상 데이터\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "origin = load_data('game_usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4f15a",
   "metadata": {},
   "source": [
    "### [3] 데이터 전처리\n",
    "- 종속변수 제거 + 데이터 표준화\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fea518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time spent</th>\n",
       "      <th>game level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250733</td>\n",
       "      <td>1.474805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326494</td>\n",
       "      <td>0.606546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.611500</td>\n",
       "      <td>0.795456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470801</td>\n",
       "      <td>1.674613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.405187</td>\n",
       "      <td>-1.558652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time spent  game level\n",
       "0   -0.250733    1.474805\n",
       "1    0.326494    0.606546\n",
       "2   -0.611500    0.795456\n",
       "3    0.470801    1.674613\n",
       "4   -1.405187   -1.558652"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df=DataFrame(scaler.fit_transform(origin),columns = origin.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc15c75",
   "metadata": {},
   "source": [
    "## #02 min_samples 고정\n",
    "\n",
    "## 실무 기준 규칙\n",
    "\n",
    "- 일반 데이터: `min_samples = 5 ~ 10`\n",
    "- 차원(d) 기준 경험적 선정 (아래 표 참고)\n",
    "\n",
    "| 차원 수 | 권장 min_samples |\n",
    "|-------|------------------|\n",
    "| 2 ~ 3 | 3 ~ 6 |\n",
    "| 5 ~ 10 | 8 ~ 15 |\n",
    "| 10 이상 | 15 이상 |\n",
    "\n",
    "> 본 실험에서는 **차원 수가 20**이므로  \n",
    "> `min_samples = 3`으로 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b09d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07551a",
   "metadata": {},
   "source": [
    "## #03. k 최근접 이웃을 통한 eps 값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9d3f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps:0.41251429498079606\n"
     ]
    }
   ],
   "source": [
    "# k = min_samples 설정\n",
    "k=min_samples\n",
    "\n",
    "\n",
    "#각 점에 대해 k 번쨰 최근접 이웃 거리 계산\n",
    "neighbors = NearestNeighbors (n_neighbors=k)\n",
    "neighbors_fit = neighbors.fit(df)\n",
    "\n",
    "#이떄 distance 는 각 데이터 포인트가 k 번째까지의 포인트와의 거리를 가까운 순서대로 리스트로 가지고 있음\n",
    "distance ,indices = neighbors_fit.kneighbors(df)\n",
    "\n",
    "\n",
    "#모든 점의 거리 값을 가까운 순서대로 정렬 (오름차순)\n",
    "s_distance = np.sort(distance,axis=0)\n",
    "\n",
    "\n",
    "#각 데이터 포인트로부터의 거리 추출\n",
    "target = s_distance[:,k-1]  #k 번째 이웃은 k-1 번쨰 이웃에 존재 , 즉 가장 멀리 있는 값을 가져와서 \n",
    "\n",
    "\n",
    "#엘보우 포인트 찾기\n",
    "kl= KneeLocator(range(0,len(target)),target,curve='convex',direction='increasing')\n",
    "eps=kl.elbow_y\n",
    "\n",
    "#결과값\n",
    "print(f'eps:{eps}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34735f",
   "metadata": {},
   "source": [
    "## #03. eps 값을 기준으로 최적 eps 구간 찾기\n",
    "### [1] eps 구간 잡기\n",
    "eps 기준 -30% ~ +30% 구간을 5% 단위로 증가하는 구간 산정 (분석가 주관에 따라 구간과 증가값 설정 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40af735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28876001, 0.30938572, 0.33001144, 0.35063715, 0.37126287,\n",
       "       0.39188858, 0.41251429, 0.43314001, 0.45376572, 0.47439144,\n",
       "       0.49501715, 0.51564287, 0.53626858, 0.5568943 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_ratio = 0.3\n",
    "step_ratio=0.05\n",
    "\n",
    "eps_min = eps*(1-delta_ratio)\n",
    "eps_max=eps*(1+delta_ratio)\n",
    "step=eps*step_ratio\n",
    "\n",
    "\n",
    "eps_grid = np.arange(eps_min,eps_max+step,step)\n",
    "eps_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ba9dd",
   "metadata": {},
   "source": [
    "### [2] eps 별 DBSCAN 결과 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653cb8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(0.2887600064865572): array([-1,  0,  1, -1,  2,  1, -1,  3,  4,  3, -1,  8,  5,  6, -1,  5,  7,\n",
       "         5,  1,  6,  8,  9, 10,  8,  5,  1,  1,  5,  4,  6,  0,  1,  4,  5,\n",
       "         7,  1,  3,  4,  2,  1,  4,  7,  1, -1,  9,  0,  1,  3, -1, 11,  4,\n",
       "        10, 11, -1, -1, -1,  2,  1,  9, -1, 11,  0, -1,  6,  3,  0,  3, -1,\n",
       "         3,  6,  1, -1, -1,  4, -1, 10, -1,  0,  5,  6,  2,  8,  3,  1, -1,\n",
       "        -1,  1,  3,  5, 10,  0, -1,  4, -1, -1, -1,  3,  1, 10,  4]),\n",
       " np.float64(0.309385721235597): array([ 0,  1,  2, -1,  3,  2,  4,  4,  5,  4, -1,  6,  7,  4, -1,  7,  8,\n",
       "         7,  2,  4,  6,  8,  9,  6,  7,  2,  2,  7,  5,  4,  1,  2,  5,  7,\n",
       "         8,  2,  4,  5,  3,  2,  5,  8,  2, 11,  8,  1,  2,  4,  1, 10,  5,\n",
       "         9, 10, -1, -1,  2,  3,  2,  8, -1, 10,  1, 11,  4,  4,  1,  4, -1,\n",
       "         4,  4,  2, -1, -1,  5, -1,  9,  0,  1,  7,  4,  3,  6,  4,  2, -1,\n",
       "        11,  2,  4,  7,  9,  1, -1,  5, -1, -1,  0,  4,  2,  9,  5]),\n",
       " np.float64(0.3300114359846368): array([ 0,  0,  1, -1,  2,  1,  3,  3,  3,  3,  1,  4,  5,  3, -1,  5,  6,\n",
       "         5,  1,  3,  4,  6,  7,  4,  5,  1,  1,  5,  3,  3,  0,  1,  3,  5,\n",
       "         6,  1,  3,  3,  2,  1,  3,  6,  1,  8,  6,  0,  1,  3,  0,  9,  3,\n",
       "         7,  9, -1, -1,  1,  2,  1,  6,  8,  9,  0,  8,  3,  3,  0,  3, -1,\n",
       "         3,  3,  1, -1, -1,  3, -1,  7,  0,  0,  5,  3,  2,  4,  3,  1, -1,\n",
       "         8,  1,  3,  5,  7,  0,  8,  3,  1, -1,  0,  3,  1,  7,  3]),\n",
       " np.float64(0.3506371507336766): array([ 0,  0,  1, -1,  2,  1,  3,  3,  3,  3,  1,  4,  5,  3, -1,  5,  6,\n",
       "         5,  1,  3,  4,  6,  7,  4,  5,  1,  1,  5,  3,  3,  0,  1,  3,  5,\n",
       "         6,  1,  3,  3,  2,  1,  3,  6,  1,  4,  6,  0,  1,  3,  0,  7,  3,\n",
       "         7,  7, -1, -1,  1,  2,  1,  6,  4,  7,  0,  4,  3,  3,  0,  3, -1,\n",
       "         3,  3,  1, -1, -1,  3, -1,  7,  0,  0,  5,  3,  2,  4,  3,  1, -1,\n",
       "         4,  1,  3,  5,  7,  0,  4,  3,  1, -1,  0,  3,  1,  7,  3]),\n",
       " np.float64(0.37126286548271636): array([ 0,  0,  1, -1,  2,  1,  1,  1,  1,  1,  1,  3,  4,  1, -1,  4,  3,\n",
       "         4,  1,  1,  3,  3,  5,  3,  4,  1,  1,  4,  1,  1,  0,  1,  1,  4,\n",
       "         3,  1,  1,  1,  2,  1,  1,  3,  1,  3,  3,  0,  1,  1,  0,  5,  1,\n",
       "         5,  5, -1,  3,  1,  2,  1,  3,  3,  5,  0,  3,  1,  1,  0,  1, -1,\n",
       "         1,  1,  1, -1, -1,  1,  3,  5,  0,  0,  4,  1,  2,  3,  1,  1,  5,\n",
       "         3,  1,  1,  4,  5,  0,  3,  1,  1, -1,  0,  1,  1,  5,  1]),\n",
       " np.float64(0.39188858023175616): array([ 0,  0,  1,  4,  2,  1,  1,  1,  1,  1,  1,  3,  2,  1,  4,  2,  3,\n",
       "         2,  1,  1,  3,  3,  5,  3,  2,  1,  1,  2,  1,  1,  0,  1,  1,  2,\n",
       "         3,  1,  1,  1,  2,  1,  1,  3,  1,  3,  3,  0,  1,  1,  0,  5,  1,\n",
       "         5,  5, -1,  3,  1,  2,  1,  3,  3,  5,  0,  3,  1,  1,  0,  1, -1,\n",
       "         1,  1,  1,  3, -1,  1,  3,  5,  0,  0,  2,  1,  2,  3,  1,  1,  5,\n",
       "         3,  1,  1,  2,  5,  0,  3,  1,  1,  4,  0,  1,  1,  5,  1]),\n",
       " np.float64(0.41251429498079595): array([ 0,  0,  0,  2,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  2,  1,  0,\n",
       "         1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, -1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.43314000972983574): array([ 0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  2,  0,  1,  2,  0,\n",
       "         2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  2,  0,  0,  0,  0,  0,  2,\n",
       "         0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, -1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  2,  0,  2,  0,  0,  0,  0,\n",
       "         0,  0,  0,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.45376572447887553): array([ 0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  2,  0,  1,  2,  0,\n",
       "         2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  2,  0,  0,  0,  0,  0,  2,\n",
       "         0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, -1,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  2,  0,  2,  0,  0,  0,  0,\n",
       "         0,  0,  0,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.4743914392279153): array([ 0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  2,  0,  1,  2,  0,\n",
       "         2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  2,  0,  0,  0,  0,  0,  2,\n",
       "         0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  2,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  2,  0,  2,  0,  0,  0,  0,\n",
       "         0,  0,  0,  2,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.4950171539769551): array([ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "         1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.5156428687259949): array([ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "         1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.5362685834750347): array([ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "         1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " np.float64(0.5568942982240745): array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict={}\n",
    "\n",
    "for eps in eps_grid:\n",
    "  estimator = DBSCAN(eps=eps,min_samples=min_samples)\n",
    "  labels_dict[eps] = estimator.fit_predict(df)\n",
    "\n",
    "\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7cdaf",
   "metadata": {},
   "source": [
    "### [3] eps 별 기본 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "\n",
    "for eps in eps_grid:\n",
    "  labels = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
